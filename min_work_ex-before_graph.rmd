### Setup
```{r, echo=F, message=F}
library(tidygeocoder)
library(tidyverse)
library(broom)
library(dplyr)
library(rafalib)
library(plotly)

# TODO: Is there a chance where these libraries are loaded twice?
library(rvest)
library(lubridate)

setwd("~/DATA1901_Project_2")
getwd()
```

### Creating Data Frames for a general suburb
```{r}
# HOUSE_SCRAPPING
# adapted from https://embracingtherandom.com/r/web-scraping/rent-scraping/
house_scraping <- function(location = "2151/Parramatta/"){
  
  
  # determine how many pages to scroll through 

   url <- paste0("https://www.auhouseprices.com/sold/list/NSW/", 
                location, 
                "1/?type=townhouse&ymin=0&ymax=0&bmin=0&bmax=0&pmin=0&pmax=0&sort=date&kw=") # type set to townhouse, no other filtering
  
  webpage <- read_html(url)
  
  # get the number of properties and the number of property displayed on each page 
  find_page_number <- webpage  %>%  html_nodes("h2") %>%  html_text() 
  find_page_number <- find_page_number[1]
  numbers <- as.numeric(regmatches(find_page_number, gregexpr("[0-9]+", find_page_number))[[1]])
  end_page <- ceiling(numbers[3] / numbers[2]) # number of total properties / number on page  = total number of pages
  
  
  df <- NULL
  
  for (thispage in c(1:end_page)){
    
    if (thispage %% 5 == 0){
      print(paste0( "Processing page ", thispage) )
    }
    
    # get website text
    url <- paste0("https://www.auhouseprices.com/sold/list/NSW/", 
                  location, 
                  thispage, 
                  "/?type=townhouse&ymin=0&ymax=0&bmin=0&bmax=0&pmin=0&pmax=0&sort=date&kw=") # type set to townhouse, no other filtering 
    webpage <- read_html(url)
    
    result <- webpage  %>%  html_nodes("li") %>%  html_text() 
    
    # end of the relevant content 
    result <-  result[ 1: grep("current", result) ]
    # remove the redundant "listed price" 
    result <-  result[ !grepl("List", result) ]
    # remove the price listed with rent
    result <-  result[ !grepl("Rent", result) ]
    
    # filter information on price and number of bedroom/bathroom/carspace
    price_bedroom  <- result[ grep("\\$", result)]
    price_bedroom <- strsplit( price_bedroom , "\\$")
    bedroom <- lapply(price_bedroom, `[`, 1)
    bedroom <- strsplit(unlist( trimws( bedroom) ) , "\\s+")
    
    price <-  lapply(price_bedroom, `[`, 2)
    price <- trimws(price)
    price <- as.numeric(gsub(",","", price ))
    
    
    # filter information on sold month and year
    # note sometimes the price is not listed , therefore only get the ones with the price 
    timesold  <- result[ grep("\\$", result)-1]
    timesold <-  trimws( gsub("Sold on","", timesold )) 
    
    # whether to use day month year or just month year
    timesold <- lapply(timesold , function(x){
      check_format <- strsplit(x, "\\s")
      if (length(check_format[[1]]) == 3){
        x <- dmy(x)
      }else if (length(check_format[[1]]) == 2){
        x <- my(x)
      }else{
        x <-  as.Date(paste0(x, "-01-01"))
      }
      x
    })
    timesold <- do.call("c", timesold)
    
    # get address of these properties
    address <- webpage  %>%  html_nodes("h4") %>%  html_text() 
    # end of the relevant content 
    address <-  address[ 1: grep("Auction History", address) -1 ]
    
    
    #decide which address contain sold price  
    sold_info <- grep("Sold on", result) #entry with sold info
    price_info <- grep("\\$", result) #entry with price info
    contain_price <- sold_info  %in% c(price_info-1) #for every sold entry, the immediate next row should be price, if not, then this sold entry does not have price record 
    address <- address[contain_price] #only record those property that has price recorded
    
    temp_df <- data.frame( address = address, 
                           bedroom = as.numeric( unlist( lapply( bedroom, `[`, 1) ) ) , 
                           bathroom = as.numeric(  unlist( lapply( bedroom, `[`, 2) )) ,  
                           carspace =  as.numeric( unlist( lapply( bedroom, `[`, 3) )), 
                           soldprice = price ,
                           yearsold =timesold )
    
    df <- rbind(df, temp_df)
  }
  
  return(df)
}
```

### Before generalization
```{r}
df_eastwood <- house_scraping( location = "2122/eastwood/")
l_eastwood <- df_eastwood%>% geocode(address, method = 'arcgis', lat=latitude, long=longitude)

#####
library(geosphere)
distance_between <- function(lat1, lon1, lat2, lon2) {
  dist <- distHaversine(c(lon1, lat1), c(lon2, lat2))
  return(dist)
}
#####
data_distance_between <- function(lat, lon, fixed_lat, fixed_lon) {
  dist <- distHaversine(c(lon, lat), c(fixed_lon, fixed_lat))
  return(dist)
}
#####
eastwood_lat <- -33.7899
eastwood_lon <- 151.0821
l_eastwood_dist <- data.frame(l_eastwood, distance_to_train_station = apply(l_eastwood[,c("latitude","longitude")], 1, function(x) data_distance_between(x[1], x[2], eastwood_lat, eastwood_lon)))
```

